{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steepest Hill Climbing\n",
    "---\n",
    "\n",
    "In this notebook, we will train hill climbing with adaptive noise scaling with OpenAI Gym's Cartpole environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define the Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation space: Box(4,)\n",
      "action space: Discrete(2)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "print('observation space:', env.observation_space)\n",
    "print('action space:', env.action_space)\n",
    "\n",
    "class Policy():\n",
    "    def __init__(self, s_size=4, a_size=2, w=None):\n",
    "        self.s_size = s_size\n",
    "        self.a_size = a_size\n",
    "        if w is None:\n",
    "            self.w = np.random.rand(s_size, a_size)  # weights for simple linear policy: state_space x action_space\n",
    "        else:\n",
    "            self.w = w\n",
    "        \n",
    "    def forward(self, state):\n",
    "        x = np.dot(state, self.w)\n",
    "        return np.exp(x) / sum(np.exp(x)) # Softmax\n",
    "    \n",
    "    def act(self, state):\n",
    "        probs = self.forward(state)\n",
    "        #action = np.random.choice(self.a_size, p=probs) # option 1: stochastic policy\n",
    "        action = np.argmax(probs)              # option 2: deterministic policy\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the Agent with Stochastic Policy Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(policy, env, gamma=.999, max_t=1000):\n",
    "    \"\"\"\n",
    "        Implement the policy on the gym environment.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        policy: Policy\n",
    "            Policy being executed.\n",
    "        env: Gym Environment\n",
    "            Environment being executed\n",
    "        gamma: float\n",
    "            penalty for later rewards\n",
    "    \"\"\"\n",
    "    rewards = []\n",
    "    state = env.reset()\n",
    "    for t in range(max_t):\n",
    "        action = policy.act(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        if done:\n",
    "            break \n",
    "    discounts = [gamma ** i for i in range(len(rewards) + 1)]\n",
    "    R = sum([a * b for a, b in zip(discounts, rewards)])\n",
    "    \n",
    "    return [R, sum(rewards)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment solved in 39 episodes!\tAverage Score: 195.08\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def steep_hill_climbing(n_episodes=1000, max_t=1000, gamma=.9999, print_every=100, pop_size=10,\n",
    "                        noise_scale=1.25, noise_mult=1, max_noise=2, min_noise=1e-4):\n",
    "    \"\"\"Implementation of steep hill climbingwith apdaptive noise.\n",
    "        \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        gamma (float): discount rate\n",
    "        print_every (int): how often to print average score (over last 100 episodes)\n",
    "        pop_size (int): number of noised agents\n",
    "    \"\"\"\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    best_R = -np.Inf\n",
    "    best_w = Policy().w\n",
    "    all_scores = []\n",
    "    for i_episode in range(1, n_episodes + 1):\n",
    "        policies = [Policy(w=best_w + noise_mult * np.random.rand(*best_w.shape)) for p in range(pop_size)]\n",
    "        scores_pop = np.array([run_episode(policy, env, gamma=gamma) for policy in policies])\n",
    "        all_scores += list(scores_pop)\n",
    "        best_index = scores_pop[:, 0].argmax()\n",
    "        local_best_R = scores_pop[:, 0][best_index]\n",
    "        local_best_w = policies[best_index].w\n",
    "        if local_best_R >= best_R: # found better weights\n",
    "            best_R = local_best_R\n",
    "            best_w = local_best_w\n",
    "            noise_mult = max(min_noise, noise_mult / noise_scale)\n",
    "        else: # did not find better weights\n",
    "            noise_mult = min(max_noise, noise_scale * noise_scale)\n",
    "        scores_deque.append(scores_pop[:, 1][best_index])\n",
    "        scores.append(scores_pop[:, 1][best_index])\n",
    "#         import pdb;pdb.set_trace()\n",
    "        if i_episode % print_every == 0:\n",
    "            print('Episode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "        if np.mean(scores_deque) >= 195.0:\n",
    "            print('Environment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(max(i_episode, i_episode-100), np.mean(scores_deque)))\n",
    "            break\n",
    "        \n",
    "    return scores, Policy(w=best_w), all_scores\n",
    "            \n",
    "scores, policy, all_scores = steep_hill_climbing(pop_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plot the Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Watch a Smart Agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "state = env.reset()\n",
    "for t in range(200):\n",
    "    action = policy.act(state)\n",
    "    env.render()\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break \n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
